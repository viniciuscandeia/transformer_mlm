{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1ee2d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do DataFrame de Treino: 596\n",
      "Tamanho do DataFrame de Teste/Validação: 150\n",
      "Tamanho do vocabulário: 6420\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Para o modelo HMM\n",
    "from hmmlearn import hmm\n",
    "\n",
    "\n",
    "def get_text_list_from_files(files):\n",
    "    \"\"\"Lê e retorna uma lista de textos a partir de uma lista de arquivos.\"\"\"\n",
    "    texts = []\n",
    "    for file_path in files:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            texts.append(file.read())\n",
    "    return texts\n",
    "\n",
    "def get_data_from_text_files(folder_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Carrega os arquivos de texto a partir de uma pasta e embaralha os dados.\"\"\"\n",
    "    files = glob.glob(os.path.join(\"musicas\", folder_name, \"*.txt\"))\n",
    "    texts = get_text_list_from_files(files)\n",
    "    df = pd.DataFrame({\"lyric\": texts})\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Carregando os dados de treino e validação (ajuste as pastas conforme a organização dos seus arquivos)\n",
    "train_df = get_data_from_text_files(\"train\")    \n",
    "test_df = get_data_from_text_files(\"test\")\n",
    "\n",
    "print(f\"Tamanho do DataFrame de Treino: {len(train_df)}\")\n",
    "print(f\"Tamanho do DataFrame de Teste/Validação: {len(test_df)}\")\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Aplica uma limpeza simples no texto: remoção de tags HTML, \n",
    "    conversão para minúsculas e remoção de pontuações.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<br\\s*/?>\", \" \", text)\n",
    "    # Remove pontuações definidas na expressão\n",
    "    text = re.sub(r\"[!#$%&'()*+,-./:;<=>?@\\^_`{|}~]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def tokenize(text: str) -> list:\n",
    "    \"\"\"Tokeniza o texto em palavras usando split básico.\"\"\"\n",
    "    text = clean_text(text)\n",
    "    return text.split()\n",
    "\n",
    "def build_vocab(texts: list, vocab_size: int = 30000):\n",
    "    \"\"\"Constroi o vocabulário a partir dos textos tokenizados. Se o vocabulário \n",
    "       exceder 'vocab_size', usa os tokens mais frequentes.\"\"\"\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = tokenize(text)\n",
    "        counter.update(tokens)\n",
    "    # Seleciona os tokens mais frequentes (caso haja o parâmetro 'vocab_size')\n",
    "    most_common = counter.most_common(vocab_size)\n",
    "    vocab = [token for token, _ in most_common]\n",
    "    \n",
    "    # Cria mapeamentos: token -> ID e ID -> token (reserve o ID 0 para <unk>)\n",
    "    token2id = {token: idx+1 for idx, token in enumerate(vocab)}\n",
    "    token2id[\"<unk>\"] = 0\n",
    "    id2token = {idx: token for token, idx in token2id.items()}\n",
    "    return token2id, id2token\n",
    "\n",
    "# Constrói o vocabulário usando os dados de treino\n",
    "all_train_texts = train_df['lyric'].tolist()\n",
    "token2id, id2token = build_vocab(all_train_texts, vocab_size=30000)\n",
    "print(f\"Tamanho do vocabulário: {len(token2id)}\")\n",
    "\n",
    "def text_to_sequence(text: str, token2id: dict) -> list:\n",
    "    \"\"\"Converte um texto em uma sequência de IDs, usando '<unk>' para tokens desconhecidos.\"\"\"\n",
    "    tokens = tokenize(text)\n",
    "    return [token2id.get(token, token2id[\"<unk>\"]) for token in tokens]\n",
    "\n",
    "# Converte os textos para sequências numéricas\n",
    "train_sequences = [text_to_sequence(text, token2id) for text in all_train_texts]\n",
    "test_sequences = [text_to_sequence(text, token2id) for text in test_df['lyric'].tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b1451f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo HMM definido com:\n",
      " - Número de estados ocultos: 10\n",
      " - Número de observações (tamanho do vocabulário): 6420\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Passo 3: Definir os Componentes do HMM\n",
    "# ============================\n",
    "\n",
    "# Para utilizar um HMM, precisamos de:\n",
    "# 1. Um número definido de estados ocultos: este é um hiperparâmetro a ser ajustado.\n",
    "# 2. Probabilidades iniciais (pi): a probabilidade de cada estado iniciar uma sequência.\n",
    "# 3. Matriz de transição (A): a probabilidade de transição entre estados.\n",
    "# 4. Matriz de emissão (B): a probabilidade de cada estado emitir cada token do vocabulário.\n",
    "\n",
    "# Aqui usamos a biblioteca hmmlearn para criar um modelo HMM multimonial, \n",
    "# onde as observações são os tokens (representados por seus IDs).\n",
    "\n",
    "num_states = 10  # Defina o número de estados ocultos desejado\n",
    "\n",
    "# Para treinar o HMM, precisamos de uma única sequência concatenada e \n",
    "# os tamanhos individuais de cada sequência (usado para separar as sequências)\n",
    "train_concat = np.concatenate(train_sequences)\n",
    "lengths = [len(seq) for seq in train_sequences]\n",
    "\n",
    "# Converte para o formato exigido pela biblioteca (array com shape (n_samples, 1))\n",
    "train_obs = np.array(train_concat).reshape(-1, 1)\n",
    "\n",
    "# Inicializa o modelo HMM Multinomial\n",
    "model = hmm.MultinomialHMM(n_components=num_states, n_iter=100, random_state=42, verbose=True)\n",
    "\n",
    "# Define o número de possíveis símbolos (tamanho do vocabulário)\n",
    "model.n_features = len(token2id)\n",
    "\n",
    "# O treinamento (ajuste dos parâmetros do HMM via algoritmo Baum-Welch) \n",
    "# será realizado usando o método model.fit() passando as observações e os comprimentos.\n",
    "# Exemplo de treinamento (opcional neste trecho):\n",
    "# model.fit(train_obs, lengths)\n",
    "\n",
    "print(\"Modelo HMM definido com:\")\n",
    "print(f\" - Número de estados ocultos: {num_states}\")\n",
    "print(f\" - Número de observações (tamanho do vocabulário): {model.n_features}\")\n",
    "\n",
    "# OBSERVAÇÃO:\n",
    "# - O treinamento e ajustes dos parâmetros do HMM será realizado na etapa posterior.\n",
    "# - Certifique-se de instalar a biblioteca hmmlearn (pip install hmmlearn) se ainda não estiver instalada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ba0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo HMM com o algoritmo Baum-Welch...\n",
      "Treinamento concluído!\n",
      "\n",
      "Probabilidades iniciais (startprob_):\n",
      "[3.75827206e-04 2.52932973e-05 8.59175053e-01 1.10004453e-01\n",
      " 6.31905995e-04 2.10534761e-08 2.25761909e-02 2.81102365e-06\n",
      " 8.25871809e-05 7.12585737e-03]\n",
      "\n",
      "Matriz de transição (transmat_):\n",
      "[[9.88338323e-04 3.65289340e-04 1.73500266e-02 3.04862330e-02\n",
      "  8.11936526e-04 1.73011401e-03 9.29461058e-01 2.04179991e-03\n",
      "  1.67652038e-02 5.99810008e-10]\n",
      " [2.13727610e-04 2.35801421e-03 1.36736510e-05 8.04622011e-02\n",
      "  1.49978221e-01 2.85176618e-03 5.23810633e-03 7.58879022e-01\n",
      "  1.58415166e-09 5.26600892e-06]\n",
      " [8.40592183e-02 8.16284182e-02 2.65710946e-01 7.89189640e-06\n",
      "  3.21950455e-03 2.17411797e-07 1.75289602e-03 3.33343573e-03\n",
      "  2.84225965e-03 5.57445212e-01]\n",
      " [1.05857532e-02 5.98123596e-05 1.58644890e-05 2.00007390e-07\n",
      "  8.44347055e-06 4.69412245e-02 9.41765497e-01 9.71128041e-21\n",
      "  4.87025239e-04 1.36179613e-04]\n",
      " [4.86182173e-01 8.37106956e-02 1.21342243e-02 5.00550941e-02\n",
      "  8.46464786e-17 7.77512411e-02 2.86345608e-01 1.72727225e-08\n",
      "  3.11901524e-03 7.01931949e-04]\n",
      " [1.76194405e-01 2.73589165e-04 5.41046948e-01 5.20619542e-07\n",
      "  2.56469858e-26 5.09006747e-03 4.17515142e-18 2.24725999e-04\n",
      "  2.77169740e-01 3.57384913e-09]\n",
      " [3.63335251e-04 4.09320806e-14 2.19551722e-06 8.87237525e-05\n",
      "  5.72862169e-02 4.61915389e-04 2.50826368e-01 8.36535769e-08\n",
      "  4.02362263e-16 6.90971161e-01]\n",
      " [8.40731699e-08 5.16079526e-11 1.11622105e-07 7.13178658e-05\n",
      "  4.10971431e-06 6.22451317e-04 9.97829622e-01 5.74765463e-07\n",
      "  1.06318315e-04 1.36541059e-03]\n",
      " [8.58422315e-03 1.77547880e-15 1.76141972e-03 1.15603806e-05\n",
      "  2.03056288e-06 1.22094532e-09 2.26791848e-09 5.91129912e-01\n",
      "  3.98510495e-01 3.55473795e-07]\n",
      " [1.61815620e-03 5.99248318e-01 1.07015200e-01 5.43459451e-07\n",
      "  2.47245710e-05 7.31087136e-06 3.08750908e-03 1.87620885e-01\n",
      "  1.01377344e-01 9.73978354e-09]]\n",
      "\n",
      "Matriz de emissão (emissionprob_):\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "\n",
      "Sequência original (primeiros 20 tokens): [27, 140, 82, 0, 1, 3, 44, 24, 9, 49, 18, 135, 209, 754, 27, 7, 2, 12, 0, 140]\n",
      "\n",
      "Mascarando o token na posição 82 (token original: 59)\n",
      "\n",
      "Token predito (ID): None (Log Likelihood: -inf)\n",
      "Token predito (texto): <desconhecido>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# ============================\n",
    "# Passo 4: Estimar os Parâmetros do HMM\n",
    "# ============================\n",
    "\n",
    "print(\"Treinando o modelo HMM com o algoritmo Baum-Welch...\")\n",
    "\n",
    "# Crie o modelo definindo também n_features no construtor,\n",
    "# onde n_features é o tamanho do vocabulário (número de símbolos discretos)\n",
    "num_states = 10  # Número de estados ocultos\n",
    "vocab_size = len(token2id)  # Tamanho do vocabulário\n",
    "\n",
    "# Inicializa o modelo HMM Multinomial com n_components (estados)\n",
    "model = hmm.MultinomialHMM(n_components=num_states, n_iter=100)\n",
    "\n",
    "# Treinamento do HMM usando as observações concatenadas e os comprimentos individuais das sequências\n",
    "model.fit(train_obs, lengths)\n",
    "print(\"Treinamento concluído!\\n\")\n",
    "\n",
    "# Exibindo alguns parâmetros aprendidos (opcional)\n",
    "print(\"Probabilidades iniciais (startprob_):\")\n",
    "print(model.startprob_)\n",
    "print(\"\\nMatriz de transição (transmat_):\")\n",
    "print(model.transmat_)\n",
    "print(\"\\nMatriz de emissão (emissionprob_):\")\n",
    "print(model.emissionprob_)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# Passo 5: Previsão de Tokens (Inferência)\n",
    "# ============================\n",
    "\n",
    "def predict_masked_token(sequence, mask_index, model, candidate_tokens=None):\n",
    "    \"\"\"\n",
    "    Dada uma sequência de IDs de tokens com um token mascarado (placeholder),\n",
    "    essa função substitui o token na posição 'mask_index' por cada candidato e\n",
    "    calcula o log likelihood da sequência resultante. Retorna o token que maximiza\n",
    "    a probabilidade da sequência.\n",
    "\n",
    "    Args:\n",
    "        sequence: lista de inteiros representando os tokens (com o token mascarado).\n",
    "        mask_index: índice na sequência onde o token foi mascarado.\n",
    "        model: modelo HMM treinado (hmm.MultinomialHMM).\n",
    "        candidate_tokens: lista de IDs candidatos a substituir o token mascarado.\n",
    "            Se None, utiliza todos os tokens do vocabulário (exceto o <unk> com ID 0).\n",
    "\n",
    "    Retorna:\n",
    "        best_token: o ID do token que maximiza o log likelihood.\n",
    "        best_log_likelihood: o valor do log likelihood para a substituição escolhida.\n",
    "    \"\"\"\n",
    "    # Se não definirmos candidatos, usamos todos os tokens válidos (exceto o ID 0, reservado para <unk>)\n",
    "    if candidate_tokens is None:\n",
    "        candidate_tokens = list(range(1, model.n_features))\n",
    "    best_token = None\n",
    "    best_log_likelihood = -np.inf  # Valor inicial para comparação\n",
    "    for token in candidate_tokens:\n",
    "        new_sequence = sequence.copy()\n",
    "        new_sequence[mask_index] = token\n",
    "        X = np.array(new_sequence).reshape(-1, 1)\n",
    "        # Calcula o log likelihood da sequência com a substituição\n",
    "        logL = model.score(X)\n",
    "        if logL > best_log_likelihood:\n",
    "            best_log_likelihood = logL\n",
    "            best_token = token\n",
    "    return best_token, best_log_likelihood\n",
    "\n",
    "# Exemplo de uso:\n",
    "# Seleciona uma sequência de teste e escolhe aleatoriamente uma posição para \"mascarar\"\n",
    "test_sequence = test_sequences[0]  # Utilizando a primeira sequência de teste\n",
    "print(\"\\nSequência original (primeiros 20 tokens):\", test_sequence[:20])\n",
    "\n",
    "if len(test_sequence) > 0:\n",
    "    # Seleciona um índice aleatório para mascarar\n",
    "    mask_idx = random.randint(0, len(test_sequence) - 1)\n",
    "    print(f\"\\nMascarando o token na posição {mask_idx} (token original: {test_sequence[mask_idx]})\")\n",
    "    \n",
    "    original_token = test_sequence[mask_idx]\n",
    "    masked_sequence = test_sequence.copy()\n",
    "    # Usamos -1 como placeholder para o token mascarado\n",
    "    masked_sequence[mask_idx] = -1\n",
    "\n",
    "    # Prediz o token que preenche melhor essa posição\n",
    "    predicted_token, ll = predict_masked_token(masked_sequence, mask_idx, model)\n",
    "    print(f\"\\nToken predito (ID): {predicted_token} (Log Likelihood: {ll})\")\n",
    "    \n",
    "    # Converte o ID do token predito para o token em texto (usando o dicionário id2token)\n",
    "    token_text = id2token.get(predicted_token, \"<desconhecido>\")\n",
    "    print(\"Token predito (texto):\", token_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
