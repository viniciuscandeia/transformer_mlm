{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Projeto\n",
    "\n",
    "Este projeto desenvolverá um modelo transformer BERT e o treinará utilizando a tarefa de Masked Language Model (MLM), aplicado ao contexto das músicas brasileiras de forró.\n",
    "\n",
    "Para isso, foi utilizado o dataset de: [inserir link do dataset]"
   ],
   "id": "e86385d09c2aa532"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Teoria\n",
    "\n",
    "### Transformer\n",
    "\n",
    "- Encoder: O Encoder recebe a sequência de entrada (por exemplo, uma frase em português) e a processa para criar uma representação vetorial de alta qualidade dessa sequência. Essa representação captura o significado e o contexto de cada palavra em relação às outras palavras da frase.\n",
    "- Decoder: O Decoder recebe a representação gerada pelo Encoder e a utiliza para gerar uma sequência de saída (por exemplo, a tradução da frase para o inglês).\n",
    "\n",
    "### Modelo BERT\n",
    "\n",
    "Bidirectional Encoder Representations from Transformers\n",
    "\n",
    "1. Bloco transformer com componentes/operacoes Multi-Head Self-Attention, Feed Foward Network e dropout.\n",
    "\n",
    "2. Customização do modelo, definindo como calcular as metricas que serao utilizadas, neste caso calculando a perda com Sparse Categorical Crossentropy e atualizando com a média da perda.\n",
    "\n",
    "3. Construção do modelo BERT para o mlm.\n",
    "\n",
    "4. Callback para a geração de texto para tokens mascarados e apresentação de resultados.\n",
    "\n",
    "### Masked Language Model\n",
    "\n",
    "Um Masked Language Model (MLM) é um tipo de modelo de linguagem amplamente utilizado em processamento de linguagem natural.\n",
    "\n",
    "Durante o treinamento, uma parte dos tokens (palavras ou subpalavras) no texto de entrada é substituída por um token especial de máscara, como \"[MASK]\". O objetivo do modelo é prever corretamente quais eram os tokens originais que foram mascarados.\n",
    "\n",
    "Essa estratégia obriga o modelo a aprender contextos ricos e relações entre as palavras, o que é fundamental para o desempenho em diversas tarefas, como análise de sentimentos, tradução, e resposta a perguntas. Modelos famosos que utilizam essa técnica incluem o BERT, que demonstrou ganhos significativos em várias benchmarks de NLP .\n",
    "\n"
   ],
   "id": "23288c2911f7f233"
  },
  {
   "cell_type": "markdown",
   "id": "c4bed58b15c8e73d",
   "metadata": {},
   "source": [
    "## Configuração para o projeto\n",
    "\n",
    "Importanto as bibliotecas necesssárias para o desenvolvimento do projeto."
   ]
  },
  {
   "cell_type": "code",
   "id": "a89620b2e2393cb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:48.879881Z",
     "start_time": "2025-04-09T13:53:48.862904Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ[ \"KERAS_BACKEND\" ] = \"torch\"  # or jax, or tensorflow\n",
    "\n",
    "import keras_hub\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from pprint import pprint"
   ],
   "outputs": [],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:48.927182Z",
     "start_time": "2025-04-09T13:53:48.913619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Identificar se está usando a CPU ou GPU no PyTorch\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "print( f\"Using device: {device}\" )"
   ],
   "id": "a5efb95b0d0e627",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "id": "6cce974cf0c26a19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:48.973455Z",
     "start_time": "2025-04-09T13:53:48.963463Z"
    }
   },
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    MAX_LEN = 256\n",
    "    BATCH_SIZE = 16  #32\n",
    "    LR = 0.0001  #0.001\n",
    "    VOCAB_SIZE = 30000\n",
    "    EMBED_DIM = 128\n",
    "    NUM_HEAD = 8  # used in bert model\n",
    "    FF_DIM = 128  # used in bert model\n",
    "    NUM_LAYERS = 1\n",
    "\n",
    "\n",
    "config = Config()"
   ],
   "outputs": [],
   "execution_count": 125
  },
  {
   "cell_type": "markdown",
   "id": "39422ab42f331838",
   "metadata": {},
   "source": [
    "# Carregando os dados\n",
    "\n",
    "Primeiro, vamos carregar os dados que estão na pasta \"musicas\".\n",
    "\n",
    "Duas funções serão utilizadas para isso:\n",
    "\n",
    "- Uma irá criar uma lista contendo o conteúdo dos arquivos.\n",
    "- A outra ficará responsável por criar um dataframe."
   ]
  },
  {
   "cell_type": "code",
   "id": "822b332050609de1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:49.207511Z",
     "start_time": "2025-04-09T13:53:48.993452Z"
    }
   },
   "source": [
    "def get_text_list_from_files( files ) -> list[ str ]:\n",
    "    \"\"\"\n",
    "       Esta função irá retornar uma lista contendo todas as frases dos arquivos.\n",
    "    \"\"\"\n",
    "    text_list: list[ str ] = [ ]\n",
    "    for name in files:\n",
    "        with open( name, \"r\", encoding = \"utf-8\" ) as f:\n",
    "            # Lê o conteúdo completo do arquivo; se houver várias linhas e desejar cada linha\n",
    "            # como exemplo separado, use um loop for sobre f.\n",
    "            text_list.append( f.read() )\n",
    "    return text_list\n",
    "\n",
    "\n",
    "def get_data_from_text_files( folder_name: str ):\n",
    "    \"\"\"\n",
    "    Retorna um dataframe contendo todas as letras dos arquivos.\n",
    "\n",
    "    :param folder_name: Nome da pasta.\n",
    "    :type folder_name: str\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Arquivos de texto que serão utilizados\n",
    "    files = glob.glob( f\"musicas/{folder_name}/*.txt\" )\n",
    "\n",
    "    # Listas com os textos\n",
    "    texts: list[ str ] = get_text_list_from_files( files )\n",
    "\n",
    "    # Criação de um dataframe, com coluna chamada \"lyric\"\n",
    "    df = pd.DataFrame( { \"lyric\": texts } )\n",
    "\n",
    "    # Sample -> pega uma amostra aleatória\n",
    "    # len(df) -> do tamanho do df original\n",
    "    # reset_index -> ao usar sample, o índice original das linhas é mantido\n",
    "    df = df.sample( len( df ) ).reset_index( drop = True )\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = get_data_from_text_files( \"train\" )\n",
    "test_df = get_data_from_text_files( \"test\" )\n",
    "\n",
    "print( f\"Tamanho do DataFrame de Treino: {len( train_df )}\" )\n",
    "print( f\"Tamanho do DataFrame de Teste/Validação: {len( test_df )}\" )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do DataFrame de Treino: 1444\n",
      "Tamanho do DataFrame de Teste/Validação: 361\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "id": "aa3089bbffe5c2b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:49.253518Z",
     "start_time": "2025-04-09T13:53:49.241518Z"
    }
   },
   "source": [
    "train_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               lyric\n",
       "0  Tá ruim fingir que tá tudo bem Tentei colocar ...\n",
       "1  Olha que é papo de pegada não é papo de dinhei...\n",
       "2  Liga liga liga  Eu disse que eu nunca mais pro...\n",
       "3  Alavantu pra tu anarriê pra eu Tu no teu canto...\n",
       "4  No forró do A Nós vamos amar No forró do B Nós..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tá ruim fingir que tá tudo bem Tentei colocar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Olha que é papo de pegada não é papo de dinhei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liga liga liga  Eu disse que eu nunca mais pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alavantu pra tu anarriê pra eu Tu no teu canto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No forró do A Nós vamos amar No forró do B Nós...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Padronização dos textos",
   "id": "d667f1b6a01e8362"
  },
  {
   "cell_type": "code",
   "id": "e617962188106c4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:49.348671Z",
     "start_time": "2025-04-09T13:53:49.333666Z"
    }
   },
   "source": [
    "\n",
    "def custom_standardization( input_data ):\n",
    "    \"\"\"Normalização de texto. \"\"\"\n",
    "    # Verifica o tipo para decodificar se for bytes (comum vindo de algumas fontes)\n",
    "    if isinstance( input_data, bytes ):\n",
    "        input_data = input_data.decode( \"utf-8\" )\n",
    "    # Converte para minúsculas (Python string method)\n",
    "    lowercase = input_data.lower()\n",
    "    # Remove tag <br /> usando re.sub\n",
    "    stripped_html = re.sub( \"<br />\", \" \", lowercase )\n",
    "    # Remove pontuação e caracteres especiais usando re.sub\n",
    "    # Nota: O padrão [%s] funciona com tf.strings, mas com re.sub é mais comum usar um conjunto [] diretamente.\n",
    "    # Escape os caracteres especiais se necessário dentro do conjunto.\n",
    "    # Ajuste a string de caracteres a remover conforme sua necessidade.\n",
    "    no_special_chars = re.sub( r\"[!\\\"#$%&'()*+,-./:;<=>?@\\[\\\\\\]^_`{|}~]\", \"\", stripped_html )\n",
    "    return no_special_chars"
   ],
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:49.505653Z",
     "start_time": "2025-04-09T13:53:49.444062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print( \"Padronizando textos de treino...\" )\n",
    "train_texts_raw = train_df.lyric.values.tolist()\n",
    "\n",
    "# Aplica a função a cada item da lista\n",
    "train_texts_standardized = [ custom_standardization( text ) for text in train_texts_raw ]\n",
    "\n",
    "print( \"Padronização concluída.\" )"
   ],
   "id": "ac2af9709bd22abf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padronizando textos de treino...\n",
      "Padronização concluída.\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "cell_type": "markdown",
   "id": "1413c85f5980aae3",
   "metadata": {},
   "source": [
    "## Vetorização de Texto\n",
    "\n",
    "Para um transformer, a vetorização de um texto é o processo fundamental de transformar o texto bruto em uma representação numérica que o modelo possa entender e processar. Em essência, é como traduzir a linguagem humana para a linguagem matemática que o transformer consegue trabalhar.\n",
    "\n",
    "Imagine que o transformer é um computador que só entende números. Para que ele consiga ler e compreender um texto, precisamos converter cada palavra (ou parte da palavra) em um conjunto de números. Esse conjunto de números é o que chamamos de vetor.\n",
    "\n",
    "Aqui está um detalhamento do processo de vetorização para um transformer:\n",
    "\n",
    "1. Tokenização: O primeiro passo é dividir o texto em unidades menores, chamadas tokens. Um token pode ser uma palavra inteira, parte de uma palavra (subpalavra), ou até mesmo um caractere. Por exemplo, a frase \"O gato comeu o rato\" poderia ser tokenizada como: [\"O\", \"gato\", \"comeu\", \"o\", \"rato\"].\n",
    "\n",
    "2. Criação do Vocabulário: Em seguida, é criado um vocabulário, que é uma lista de todos os tokens únicos presentes no conjunto de dados de treinamento do modelo. Cada token nesse vocabulário recebe um índice único.\n",
    "\n",
    "3. Indexação: Cada token no texto de entrada é então mapeado para o seu índice correspondente no vocabulário. Usando o exemplo anterior e supondo um vocabulário, os tokens poderiam ser convertidos em índices como: [10, 25, 50, 10, 75].\n",
    "\n",
    "4. Embedding: A etapa crucial para transformers é a criação de embeddings. Em vez de simplesmente usar os índices brutos, cada índice é transformado em um vetor denso de números reais. Esse vetor captura o significado semântico e as relações entre as palavras.\n",
    "\n",
    "    - Word Embeddings: Cada palavra (ou token) é associada a um vetor de baixa dimensionalidade (por exemplo, 512 ou 768 dimensões). Palavras com significados semelhantes tendem a ter vetores próximos no espaço vetorial. Por exemplo, os vetores para \"gato\" e \"felino\" provavelmente estarão mais próximos do que os vetores para \"gato\" e \"carro\".\n",
    "\n",
    "    - Positional Embeddings: Transformers também precisam entender a ordem das palavras em uma frase. Para isso, são adicionados embeddings posicionais aos word embeddings. Esses vetores codificam a posição de cada token na sequência, permitindo que o modelo diferencie entre \"o gato comeu o rato\" e \"o rato comeu o gato\".\n",
    "\n",
    "5. Input para o Transformer: Os vetores resultantes (a soma dos word embeddings e positional embeddings para cada token) são então alimentados como entrada para as diferentes camadas do transformer (como as camadas de atenção)."
   ]
  },
  {
   "cell_type": "code",
   "id": "7d8904fb48419e91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:49.696120Z",
     "start_time": "2025-04-09T13:53:49.684123Z"
    }
   },
   "source": [
    "def get_vectorize_layer( texts: list[ str ], vocab_size: int, max_seq: int, special_tokens: list = [ \"[MASK]\" ] ):\n",
    "    \"\"\"Build Text vectorization layer\n",
    "\n",
    "    Args:\n",
    "      texts (list): List of string i.e input texts\n",
    "      vocab_size (int): vocab size\n",
    "      max_seq (int): Maximum sequence length.\n",
    "      special_tokens (list, optional): List of special tokens. Defaults to ['[MASK]'].\n",
    "\n",
    "    Returns:\n",
    "        layers.Layer: Return TextVectorization Keras Layer\n",
    "    \"\"\"\n",
    "\n",
    "    # Criação da camada de TextVectorization\n",
    "    vectorize_layer = TextVectorization(\n",
    "            max_tokens = vocab_size,  # Define o tamanho máximo do vocabulário\n",
    "            output_mode = \"int\",  # Define que a saída deve ser uma sequência de números inteiros\n",
    "            standardize = None,  # Aplicar função de pré-processamento\n",
    "            output_sequence_length = max_seq,  # Garantir que toda sequência de saída tenha comprimento max_seq\n",
    "    )\n",
    "\n",
    "    # todo Mostrar um exemplo\n",
    "\n",
    "    # Adaptação aos textos de entrada\n",
    "    # A camada \"sabe\" como mapear palavras para números inteiros, com base nas entradas\n",
    "    vectorize_layer.adapt( texts )\n",
    "\n",
    "    # Obtem o vocabulário aprendido pelo adapt (inclui '' e '[UNK]')\n",
    "    vocab_adaptado = vectorize_layer.get_vocabulary()\n",
    "\n",
    "    # Calcula quantos tokens 'reais' (não '', não '[UNK]', não especiais) podemos manter\n",
    "    num_special_tokens = len( special_tokens )\n",
    "    # Precisamos de espaço para: '' (1), '[UNK]' (1), N palavras frequentes, M tokens especiais\n",
    "    # Tamanho total <= vocab_size\n",
    "    num_palavras_frequentes = vocab_size - 2 - num_special_tokens\n",
    "\n",
    "    # Garante que não tentemos pegar mais palavras do que as aprendidas, ou um número negativo\n",
    "    num_palavras_frequentes = max( 0, min( num_palavras_frequentes, len( vocab_adaptado ) - 2 ) )\n",
    "\n",
    "    # Pega as N palavras mais frequentes (começando do índice 2 do vocab adaptado)\n",
    "    palavras_frequentes = vocab_adaptado[ 2: 2 + num_palavras_frequentes ]\n",
    "\n",
    "    # --- CONSTRUÇÃO EXPLÍCITA DO VOCABULÁRIO FINAL ---\n",
    "    # Começa com os tokens padrão de padding e OOV\n",
    "    vocabulario_final = [ \"\", \"[UNK]\" ]\n",
    "    # Adiciona as palavras mais frequentes\n",
    "    vocabulario_final.extend( palavras_frequentes )\n",
    "    # Adiciona os tokens especiais no final\n",
    "    vocabulario_final.extend( special_tokens )\n",
    "\n",
    "    # Define o vocabulário usando a lista final CORRETAMENTE ESTRUTURADA\n",
    "    print( f\"Definindo vocabulário final explícito com ~{len( vocabulario_final )} tokens...\" )\n",
    "    vectorize_layer.set_vocabulary( vocabulario_final )\n",
    "\n",
    "    # Verificação opcional do tamanho final e índices importantes\n",
    "    vocab_real_final = vectorize_layer.get_vocabulary()\n",
    "    print( f\"Tamanho real do vocabulário após set_vocabulary: {len( vocab_real_final )}\" )\n",
    "    try:\n",
    "        print( f\"Índice de '': {vocab_real_final.index( '' )}\" )  # Deve ser 0\n",
    "        print( f\"Índice de '[UNK]': {vocab_real_final.index( '[UNK]' )}\" )  # Deve ser 1\n",
    "        for token in special_tokens:\n",
    "            print( f\"Índice de '{token}': {vocab_real_final.index( token )}\" )  # Deve estar no final\n",
    "    except ValueError as e:\n",
    "        print( f\"Erro ao verificar índices: {e}\" )  # Indica problema na construção\n",
    "\n",
    "    # Retorna a camada\n",
    "    return vectorize_layer"
   ],
   "outputs": [],
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "id": "14af57ee8c312389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:49.962725Z",
     "start_time": "2025-04-09T13:53:49.761681Z"
    }
   },
   "source": [
    "# Pegando a camada de vetorização\n",
    "vectorize_layer = get_vectorize_layer(\n",
    "        train_texts_standardized,\n",
    "        config.VOCAB_SIZE,\n",
    "        config.MAX_LEN,\n",
    "        special_tokens = [ \"[mask]\" ],\n",
    ")\n",
    "\n",
    "# Processamento de um novo dado: \"[mask]\"\n",
    "# - Aplica a função de pré-processamento\n",
    "# - Divide em token, pega seu id e cria uma sequência de comprimento config.MAX_LEN\n",
    "# - Converte o resultado para um array NumPy\n",
    "# - Pega o id do \"[mask]\"\n",
    "mask_token_id = vectorize_layer( [ \"[mask]\" ] )[ 0 ][ 0 ].item()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definindo vocabulário final explícito com ~11168 tokens...\n",
      "Tamanho real do vocabulário após set_vocabulary: 11168\n",
      "Índice de '': 0\n",
      "Índice de '[UNK]': 1\n",
      "Índice de '[mask]': 11167\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "id": "cf38423e529f2726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:49.978723Z",
     "start_time": "2025-04-09T13:53:49.968723Z"
    }
   },
   "source": [
    "def encode( texts ):\n",
    "    \"\"\" Retorna um array NumPy das sequências numéricas dos textos de entrada.\"\"\"\n",
    "    # Criação das sequências numéricas para os textos de entrada\n",
    "    # vectorize_layer retorna tensor PyTorch (no backend torch)\n",
    "    encoded_texts = vectorize_layer( texts )\n",
    "    # Retorna o tensor diretamente (pode estar na GPU)\n",
    "    return encoded_texts"
   ],
   "outputs": [],
   "execution_count": 132
  },
  {
   "cell_type": "markdown",
   "id": "7f5c334136918c96",
   "metadata": {},
   "source": [
    "### Mascaramento de Texto\n",
    "\n",
    "Em essência, o mascaramento envolve ocultar aleatoriamente algumas das palavras (ou tokens) em uma sequência de texto de entrada. O objetivo é fazer com que o modelo aprenda a prever as palavras que foram mascaradas, com base no contexto das palavras vizinhas não mascaradas.\n",
    "\n",
    "Imagine a frase: \"O gato está dormindo no tapete.\"\n",
    "\n",
    "No processo de mascaramento, poderíamos aleatoriamente escolher algumas palavras para ocultar, substituindo-as por um token especial, geralmente chamado [MASK]. Por exemplo, a frase poderia se tornar:\n",
    "\n",
    "\"O [MASK] está dormindo no [MASK].\"\n",
    "\n",
    "O modelo de linguagem, durante o treinamento, receberia essa versão mascarada da frase como entrada e teria como objetivo prever as palavras originais que foram substituídas por [MASK]. Neste caso, o modelo deveria aprender a prever \"gato\" para o primeiro [MASK] e \"tapete\" para o segundo."
   ]
  },
  {
   "cell_type": "code",
   "id": "977366761074a52b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:50.024724Z",
     "start_time": "2025-04-09T13:53:50.011724Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_masked_input_and_labels( encoded_texts_tensor: torch.Tensor, mask_token_id: int ):\n",
    "    # Pega o dispositivo do tensor de entrada (CPU ou CUDA)\n",
    "    tensor_device = encoded_texts_tensor.device\n",
    "\n",
    "    # Cria tensores aleatórios no mesmo dispositivo que a entrada\n",
    "    # torch.rand retorna valores entre 0 e 1\n",
    "    inp_mask = torch.rand( encoded_texts_tensor.shape, device = tensor_device ) < 0.15\n",
    "\n",
    "    # Não deixa realizar o mascaramento em tokens especiais (<= 2)\n",
    "    inp_mask[ encoded_texts_tensor <= 2 ] = False\n",
    "\n",
    "    # Cria um tensor de labels preenchido com -1 no mesmo dispositivo\n",
    "    # Usa torch.full para criar um tensor com um valor específico\n",
    "    labels = torch.full( encoded_texts_tensor.shape, -1, dtype = torch.long, device = tensor_device )\n",
    "\n",
    "    # Atribui os IDs originais aos labels onde a máscara é True\n",
    "    labels[ inp_mask ] = encoded_texts_tensor[ inp_mask ]\n",
    "\n",
    "    # Cria uma cópia do tensor de entrada no mesmo dispositivo\n",
    "    encoded_texts_masked = encoded_texts_tensor.clone()\n",
    "\n",
    "    # --- Lógica de mascaramento (80% [MASK], 10% Random, 10% Original) ---\n",
    "    # Máscara para os 90% que serão alterados (não os 10% que ficam originais)\n",
    "    inp_mask_change = inp_mask & (torch.rand( encoded_texts_tensor.shape, device = tensor_device ) < 0.90)\n",
    "\n",
    "    # Desses 90%, 8/9 (aprox 88.9%) serão [MASK]\n",
    "    # (Equivalente aos 80% do total original mascarado)\n",
    "    inp_mask_2mask = inp_mask_change & (torch.rand( encoded_texts_tensor.shape, device = tensor_device ) < 8 / 9)\n",
    "    encoded_texts_masked[ inp_mask_2mask ] = mask_token_id\n",
    "\n",
    "    # Os restantes 1/9 (aprox 11.1%) dos 90% alterados serão tokens aleatórios\n",
    "    # (Equivalente aos 10% do total original mascarado)\n",
    "    # torch.logical_and é mais explícito que & para tensores booleanos\n",
    "    inp_mask_2random = torch.logical_and( inp_mask_change, ~inp_mask_2mask )  # '~' é a negação booleana\n",
    "\n",
    "    # Gera inteiros aleatórios para as posições a serem randomizadas\n",
    "    num_random = inp_mask_2random.sum()  # Conta quantos True existem\n",
    "    random_words = torch.randint( 3, mask_token_id, (num_random,), dtype = torch.long, device = tensor_device )\n",
    "    encoded_texts_masked[ inp_mask_2random ] = random_words\n",
    "    # Os 10% restantes de 'inp_mask' que não estão em 'inp_mask_change' ficam inalterados por padrão\n",
    "\n",
    "    # Cria o tensor de sample_weights no mesmo dispositivo\n",
    "    sample_weights = torch.ones( labels.shape, dtype = torch.float32, device = tensor_device )  # Usar float para pesos\n",
    "    sample_weights[ labels == -1 ] = 0.0  # Atribui 0.0 (float)\n",
    "\n",
    "    # Retorna tensores PyTorch (potencialmente na GPU)\n",
    "    # Não precisamos de y_labels separados, pois 'labels' já contém os tokens originais onde não é -1\n",
    "    # E a função de perda SparseCategoricalCrossentropy ignora índices negativos se configurada corretamente\n",
    "    # ou usamos o sample_weight para zerar a perda nesses pontos.\n",
    "    # Retornaremos o original também, caso seja útil em algum outro lugar.\n",
    "    return encoded_texts_masked, encoded_texts_tensor.clone(), sample_weights  # Retorna mascarado, original, pesos"
   ],
   "outputs": [],
   "execution_count": 133
  },
  {
   "cell_type": "markdown",
   "id": "fc0c9d5289de1a13",
   "metadata": {},
   "source": [
    "## Codificação e Datasets\n",
    "\n",
    "1. Classificação de Sentimentos: Cria datasets de treinamento e teste (train_classifier_ds e test_classifier_ds) onde as revisões são codificadas e emparelhadas com seus rótulos de sentimento.\n",
    "\n",
    "2. Modelo de Linguagem Mascarada: Cria um dataset (mlm_ds) para treinar um modelo a prever palavras mascaradas em um conjunto de todas as revisões."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Treinamento do modelo BERT",
   "id": "67be1561f10b4df5"
  },
  {
   "cell_type": "code",
   "id": "5ac4d706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:50.072244Z",
     "start_time": "2025-04-09T13:53:50.058243Z"
    }
   },
   "source": [
    "def bert_module( query, key, value, i ):\n",
    "\n",
    "    #Fazer uma \"self-attention\" com multiplas cabeças\n",
    "    #self attention e uma maneira do modelo enteder as relacoes de uma sequencia de palavras\n",
    "    #por ter mais de 1 cabeça permite notar essas relacoes em diferentes partes do texto\n",
    "    attention_output = layers.MultiHeadAttention(\n",
    "            num_heads = config.NUM_HEAD,\n",
    "            key_dim = config.EMBED_DIM // config.NUM_HEAD,\n",
    "            name = \"encoder_{}_multiheadattention\".format( i ),\n",
    "    )( query, key, value )\n",
    "\n",
    "    #Dropout para ajudar na regularizacao (evitar overfitting)\n",
    "    attention_output = layers.Dropout( 0.1, name = \"encoder_{}_att_dropout\".format( i ) )(\n",
    "            attention_output\n",
    "    )\n",
    "\n",
    "    #Layer normalization da atencao que foi calculada e da entrada original\n",
    "    #serve para garantir o processo de informacao de maneira consistente, ajudando na performance e eficiencia\n",
    "    attention_output = layers.LayerNormalization(\n",
    "            epsilon = 1e-6, name = \"encoder_{}_att_layernormalization\".format( i )\n",
    "    )( query + attention_output )\n",
    "\n",
    "    # Feed-forward layer, serve para que informacoes em estagios tadios do processamento sejam\n",
    "    #enviados para estagios mais iniciais\n",
    "    ffn = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense( config.FF_DIM, activation = \"relu\" ),  #expande  dimensao para FF_DIMe ativacao ReLU\n",
    "                layers.Dense( config.EMBED_DIM ),  #volta para a dimensao original\n",
    "            ],\n",
    "            name = \"encoder_{}_ffn\".format( i ),\n",
    "    )\n",
    "\n",
    "    #aplicacao de dropout novamente\n",
    "    ffn_output = ffn( attention_output )\n",
    "    ffn_output = layers.Dropout( 0.1, name = \"encoder_{}_ffn_dropout\".format( i ) )(\n",
    "            ffn_output\n",
    "    )\n",
    "\n",
    "    #layer normalization novamente com a saida da camada de atencao\n",
    "    sequence_output = layers.LayerNormalization(\n",
    "            epsilon = 1e-6, name = \"encoder_{}_ffn_layernormalization\".format( i )\n",
    "    )( attention_output + ffn_output )\n",
    "\n",
    "    #o resultado possui a mesma dimensao da entrada porem com representacoes melhores\n",
    "    #mesmos dados porem enriquecidos de contexto\n",
    "    return sequence_output\n"
   ],
   "outputs": [],
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "id": "9af62811",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:50.120243Z",
     "start_time": "2025-04-09T13:53:50.106243Z"
    }
   },
   "source": [
    "#Funcao de perda de entropia cruzada esparsa\n",
    "#usada quando tem duas ou mais classes de label\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy( reduction = None )\n",
    "#media dos valores de perda ao longo do treinamento\n",
    "loss_tracker = keras.metrics.Mean( name = \"loss\" )\n",
    "\n",
    "\n",
    "#esta classe serve para calcular as metricas e a perda de maneira customizada\n",
    "#assim temos um controle maior do treinamento\n",
    "class MaskedLanguageModel( keras.Model ):\n",
    "\n",
    "    def compute_loss( self, x = None, y = None, y_pred = None, sample_weight = None ):\n",
    "        #ja que na funcao de perda nao tem reducao vamos ter um valor de perda pra cada exemplo\n",
    "        #entao o fazemos com que a soma total seja o que sera otimizada\n",
    "        loss = loss_fn( y, y_pred, sample_weight )\n",
    "        loss_tracker.update_state( loss, sample_weight = sample_weight )\n",
    "        return keras.ops.sum( loss )\n",
    "\n",
    "    def compute_metrics( self, x, y, y_pred, sample_weight ):\n",
    "        # Retorna um dicionario com a perda media do loss_tracker\n",
    "        return { \"loss\": loss_tracker.result() }\n",
    "\n",
    "    @property\n",
    "    def metrics( self ):\n",
    "        #este serve para que nao seja necessario o reset manual das metricas\n",
    "        # We list our `Metric` objects here so that `reset_states()` can be\n",
    "        # called automatically at the start of each epoch\n",
    "        # or at the start of `evaluate()`.\n",
    "        # If you don't implement this property, you have to call\n",
    "        # `reset_states()` yourself at the time of your choosing.\n",
    "        return [ loss_tracker ]"
   ],
   "outputs": [],
   "execution_count": 135
  },
  {
   "cell_type": "code",
   "id": "83087148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:50.214763Z",
     "start_time": "2025-04-09T13:53:50.154253Z"
    }
   },
   "source": [
    "def create_masked_language_bert_model():\n",
    "    #configura a camada de entrada para que seja uma lista de tokens INT\n",
    "    inputs = layers.Input( (config.MAX_LEN,), dtype = \"int64\" )\n",
    "\n",
    "    #converte os IDs dos tokens em vetores\n",
    "    #cava vetor tera  dimensao de EMBED_DIM\n",
    "    word_embeddings = layers.Embedding(\n",
    "            config.VOCAB_SIZE, config.EMBED_DIM, name = \"word_embedding\"\n",
    "    )( inputs )\n",
    "\n",
    "    #cria a informacao adicional das posicoes dos tokens para o modelo usando a bibliote do keras_hub\n",
    "    position_embeddings = keras_hub.layers.PositionEmbedding(\n",
    "            sequence_length = config.MAX_LEN\n",
    "    )( word_embeddings )\n",
    "\n",
    "    #combina as duas informacoes criadas, a de semantica de a de posicao\n",
    "    embeddings = word_embeddings + position_embeddings\n",
    "\n",
    "    encoder_output = embeddings\n",
    "\n",
    "    #para cada camada se aplica o bert, um bloco transformer contendo Multi-Head Self-Attention e Feed-Forward Network\n",
    "    for i in range( config.NUM_LAYERS ):\n",
    "        encoder_output = bert_module( encoder_output, encoder_output, encoder_output, i )\n",
    "\n",
    "    #camada de classificacao para o mlm, transformando a saída do encoder em predições de tokens\n",
    "    #a função de ativação softmax transforma as saídas brutas da rede neural em um vetor de probabilidades\n",
    "    mlm_output = layers.Dense( config.VOCAB_SIZE, name = \"mlm_cls\", activation = \"softmax\" )(\n",
    "            encoder_output\n",
    "    )\n",
    "\n",
    "    #criar a instancia da classe mlm que ja definimos\n",
    "    mlm_model = MaskedLanguageModel( inputs, mlm_output, name = \"masked_bert_model\" )\n",
    "\n",
    "    #otimizacao usando \"Adam\" e compilacao\n",
    "    optimizer = keras.optimizers.Adam( learning_rate = config.LR )\n",
    "    mlm_model.compile( optimizer = optimizer )\n",
    "    return mlm_model\n",
    "\n",
    "\n",
    "#mapeamento de ID para token e vice versa para facilitar interpretacao dos dados\n",
    "id2token = dict( enumerate( vectorize_layer.get_vocabulary() ) )\n",
    "token2id = { y: x for x, y in id2token.items() }"
   ],
   "outputs": [],
   "execution_count": 136
  },
  {
   "cell_type": "code",
   "id": "874798b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:50.339289Z",
     "start_time": "2025-04-09T13:53:50.247772Z"
    }
   },
   "source": [
    "#por herdar keras.callbacks.Callback pode ser usada durante o treinamento\n",
    "class MaskedTextGenerator( keras.callbacks.Callback ):\n",
    "    def __init__( self, sample_text: str, vectorize_layer, id2token, mask_token_id, top_k = 5 ):\n",
    "        super().__init__()\n",
    "        self.sample_text = sample_text\n",
    "        self.vectorize_layer = vectorize_layer\n",
    "        self.id2token = id2token\n",
    "        self.mask_token_id = mask_token_id  # Passar o ID (int)\n",
    "        self.k = top_k\n",
    "        # Vetoriza o texto de exemplo uma vez e mantém como tensor (potencialmente na GPU)\n",
    "        self.sample_tokens_tensor = self.vectorize_layer( [ self.sample_text ] )  # Retorna tensor PyTorch\n",
    "\n",
    "    def decode( self, tokens_tensor ):\n",
    "        # Converte tensor para CPU, depois NumPy, depois lista de ints para decodificar\n",
    "        if tokens_tensor.is_cuda:\n",
    "            tokens_tensor = tokens_tensor.cpu()\n",
    "        # Itera sobre os tokens no tensor numpy para decodificar\n",
    "        return \" \".join( [ self.id2token.get( int( t ), \"[UNK]\" ) for t in tokens_tensor.numpy().flatten() if t != 0 ] )\n",
    "\n",
    "    def convert_ids_to_tokens( self, token_id ):\n",
    "        # token_id já deve ser um int ou tensor 0D na CPU\n",
    "        if isinstance( token_id, torch.Tensor ):\n",
    "            token_id = token_id.item()  # Converte tensor 0D para int Python\n",
    "        return self.id2token.get( token_id, \"[UNK]\" )\n",
    "\n",
    "    def on_epoch_end( self, epoch, logs = None ):\n",
    "        print( f\"\\n--- Predição Exemplo Callback (Época {epoch + 1}) ---\" )\n",
    "        # Garante que o tensor de exemplo está no dispositivo correto para o modelo\n",
    "        # model.device não é uma propriedade padrão, mas podemos inferir ou passar o 'device'\n",
    "        model_device = next( self.model.parameters() ).device  # Pega o dispositivo do primeiro parâmetro do modelo\n",
    "        sample_tokens_on_device = self.sample_tokens_tensor.to( model_device )\n",
    "\n",
    "        # Recebe as previsões (tensor PyTorch na GPU)\n",
    "        # Use torch.no_grad() para desabilitar cálculo de gradiente na inferência\n",
    "        with torch.no_grad():\n",
    "            prediction = self.model.predict( sample_tokens_on_device, verbose = 0 )  # verbose=0 é bom aqui\n",
    "            # Se predict retornar numpy, converte para tensor\n",
    "            if isinstance( prediction, np.ndarray ):\n",
    "                prediction = torch.from_numpy( prediction ).to( model_device )\n",
    "\n",
    "        # Encontra o índice do token de máscara usando operações de tensor\n",
    "        # torch.where retorna uma tupla de tensores de índice\n",
    "        masked_indices = torch.where( sample_tokens_on_device[ 0 ] == self.mask_token_id )\n",
    "\n",
    "        # Verifica se encontrou a máscara\n",
    "        if len( masked_indices[ 0 ] ) == 0:\n",
    "            print( \"AVISO: Token de máscara não encontrado no texto de exemplo do callback.\" )\n",
    "            return\n",
    "\n",
    "        masked_index = masked_indices[ 0 ][ 0 ]  # Pega o primeiro índice encontrado\n",
    "\n",
    "        # Pega as probabilidades de predição para os tokens mascarados (ainda na GPU)\n",
    "        mask_prediction_probs = prediction[ 0, masked_index, : ]  # Probabilidades sobre todo o vocabulário\n",
    "\n",
    "        # Encontra os top K usando torch.topk (mais direto que argsort)\n",
    "        # Retorna valores (probabilidades) e índices\n",
    "        top_probs, top_indices = torch.topk( mask_prediction_probs, self.k )\n",
    "\n",
    "        # Agora, para imprimir, precisamos mover os resultados para a CPU\n",
    "        top_probs_cpu = top_probs.cpu()\n",
    "        top_indices_cpu = top_indices.cpu()\n",
    "        sample_tokens_cpu = sample_tokens_on_device.cpu()  # Para decodificar o input\n",
    "\n",
    "        # Decodifica o texto de entrada original (da CPU)\n",
    "        input_text_decoded = self.decode( sample_tokens_cpu[ 0 ] )\n",
    "\n",
    "        print( f\"Texto de Entrada: {input_text_decoded}\" )\n",
    "\n",
    "        # Itera sobre os top K resultados (na CPU)\n",
    "        for i in range( self.k ):\n",
    "            p_idx = top_indices_cpu[ i ]  # Tensor 0D na CPU\n",
    "            prob = top_probs_cpu[ i ]  # Tensor 0D na CPU\n",
    "\n",
    "            # Cria uma cópia do tensor original na CPU para substituição segura\n",
    "            tokens_pred = sample_tokens_cpu[ 0 ].clone()\n",
    "            tokens_pred[ masked_index ] = p_idx  # Substitui com o índice previsto\n",
    "\n",
    "            result = {\n",
    "                \"prediction\": self.decode( tokens_pred ),\n",
    "                \"probability\": prob.item(),  # Pega valor float do tensor 0D\n",
    "                \"predicted_mask_token\": self.convert_ids_to_tokens( p_idx ),  # Passa tensor 0D ou int\n",
    "            }\n",
    "            pprint( result )\n",
    "        print( f\"--- Fim Predição Exemplo Callback ---\" )\n",
    "\n",
    "\n",
    "generator_callback = MaskedTextGenerator(\n",
    "        sample_text = \" Você e [mask]\",\n",
    "        vectorize_layer = vectorize_layer,\n",
    "        id2token = id2token,\n",
    "        mask_token_id = mask_token_id,  # Passa o ID (int)\n",
    "        top_k = 5\n",
    ")\n",
    "\n",
    "#cria o modelo bert pra o mlm e resume com summary()\n",
    "bert_masked_model = create_masked_language_bert_model()\n",
    "bert_masked_model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"masked_bert_model\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"masked_bert_model\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ word_embedding      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │  \u001B[38;5;34m3,840,000\u001B[0m │ input_layer_12[\u001B[38;5;34m0\u001B[0m… │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ position_embedding… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │     \u001B[38;5;34m32,768\u001B[0m │ word_embedding[\u001B[38;5;34m0\u001B[0m… │\n",
       "│ (\u001B[38;5;33mPositionEmbedding\u001B[0m) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_18 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ word_embedding[\u001B[38;5;34m0\u001B[0m… │\n",
       "│                     │                   │            │ position_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_multihea… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │     \u001B[38;5;34m66,048\u001B[0m │ add_18[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],     │\n",
       "│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │            │ add_18[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],     │\n",
       "│                     │                   │            │ add_18[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_att_drop… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ encoder_0_multih… │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_19 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ add_18[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],     │\n",
       "│                     │                   │            │ encoder_0_att_dr… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_att_laye… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │        \u001B[38;5;34m256\u001B[0m │ add_19[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n",
       "│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_ffn       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │     \u001B[38;5;34m33,024\u001B[0m │ encoder_0_att_la… │\n",
       "│ (\u001B[38;5;33mSequential\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_ffn_drop… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ encoder_0_ffn[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_20 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ encoder_0_att_la… │\n",
       "│                     │                   │            │ encoder_0_ffn_dr… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_ffn_laye… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m, \u001B[38;5;34m128\u001B[0m)  │        \u001B[38;5;34m256\u001B[0m │ add_20[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n",
       "│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlm_cls (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m,       │  \u001B[38;5;34m3,870,000\u001B[0m │ encoder_0_ffn_la… │\n",
       "│                     │ \u001B[38;5;34m30000\u001B[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ word_embedding      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840,000</span> │ input_layer_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ position_embedding… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,768</span> │ word_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionEmbedding</span>) │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ word_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ position_embeddi… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_multihea… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_att_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_0_multih… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│                     │                   │            │ encoder_0_att_dr… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_att_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_ffn       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ encoder_0_att_la… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_ffn_drop… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_0_ffn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_0_att_la… │\n",
       "│                     │                   │            │ encoder_0_ffn_dr… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_0_ffn_laye… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ add_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mlm_cls (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,870,000</span> │ encoder_0_ffn_la… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">30000</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m7,842,352\u001B[0m (29.92 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,842,352</span> (29.92 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m7,842,352\u001B[0m (29.92 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,842,352</span> (29.92 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:53:50.481357Z",
     "start_time": "2025-04-09T13:53:50.374834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class LyricsDataset( Dataset ):\n",
    "    def __init__( self, texts: list[ str ], vectorize_layer, config, mask_token_id ):\n",
    "        \"\"\" Dataset PyTorch para as letras das músicas. \"\"\"\n",
    "        self.vectorize_layer = vectorize_layer\n",
    "        self.config = config\n",
    "        self.mask_token_id = mask_token_id\n",
    "\n",
    "        print( f\"Padronizando {len( texts )} textos para o Dataset PyTorch...\" )\n",
    "        self.texts_standardized = [ custom_standardization( text ) for text in texts ]\n",
    "        print( \"Padronização concluída. Vetorizando...\" )\n",
    "\n",
    "        # Vetoriza todos os textos JÁ PADRONIZADOS uma vez\n",
    "        self.encoded_texts_tensor = self.vectorize_layer( self.texts_standardized )\n",
    "        print(\n",
    "                f\"Textos vetorizados. Forma: {self.encoded_texts_tensor.shape}, Dispositivo: {self.encoded_texts_tensor.device}\"\n",
    "        )\n",
    "\n",
    "    def __len__( self ):\n",
    "        # Retorna o número total de amostras no dataset\n",
    "        return len( self.encoded_texts_tensor )\n",
    "\n",
    "    def __getitem__( self, idx ):\n",
    "        # Pega o tensor codificado para o índice solicitado\n",
    "        encoded_tensor = self.encoded_texts_tensor[ idx ]\n",
    "\n",
    "        # Aplica a função de mascaramento PyTorch\n",
    "        # Nota: get_masked_input_and_labels_pytorch espera um tensor individual aqui, não um batch\n",
    "        masked_tensor, original_tensor, sample_weight = get_masked_input_and_labels(\n",
    "                encoded_tensor,\n",
    "                self.mask_token_id\n",
    "        )\n",
    "\n",
    "        # Remove a dimensão de batch adicionada e retorna os tensores\n",
    "        return masked_tensor.squeeze( 0 ), original_tensor.squeeze( 0 ), sample_weight.squeeze( 0 )\n",
    "\n",
    "\n",
    "# --- Criação dos Datasets e DataLoaders ---\n",
    "\n",
    "# Cria instâncias do LyricsDataset passando textos RAW\n",
    "train_dataset_torch = LyricsDataset( train_df.lyric.values.tolist(), vectorize_layer, config, mask_token_id )\n",
    "val_dataset_torch = LyricsDataset( test_df.lyric.values.tolist(), vectorize_layer, config, mask_token_id )\n",
    "\n",
    "# Cria os DataLoaders (sem mudanças aqui)\n",
    "train_loader = DataLoader(\n",
    "        train_dataset_torch,\n",
    "        batch_size = config.BATCH_SIZE,\n",
    "        shuffle = True,\n",
    "        num_workers = 0,\n",
    "        pin_memory = False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "        val_dataset_torch,\n",
    "        batch_size = config.BATCH_SIZE,\n",
    "        shuffle = False,\n",
    "        num_workers = 0,\n",
    "        pin_memory = False\n",
    ")\n",
    "print( \"DataLoaders PyTorch criados.\" )"
   ],
   "id": "c091b7fd118c22e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padronizando 1444 textos para o Dataset PyTorch...\n",
      "Padronização concluída. Vetorizando...\n",
      "Textos vetorizados. Forma: torch.Size([1444, 256]), Dispositivo: cuda:0\n",
      "Padronizando 361 textos para o Dataset PyTorch...\n",
      "Padronização concluída. Vetorizando...\n",
      "Textos vetorizados. Forma: torch.Size([361, 256]), Dispositivo: cuda:0\n",
      "DataLoaders PyTorch criados.\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "cell_type": "code",
   "id": "f99975dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:57:43.518234Z",
     "start_time": "2025-04-09T13:53:50.515368Z"
    }
   },
   "source": [
    "# Calcula os passos por época para treino e validação\n",
    "# Usar len(train_df) e len(test_df) para os cálculos\n",
    "train_steps_per_epoch: int = len( train_df ) // config.BATCH_SIZE\n",
    "val_steps_per_epoch: int = len( test_df ) // config.BATCH_SIZE\n",
    "\n",
    "print( f\"Passos por época (Treino): {train_steps_per_epoch}\" )\n",
    "print( f\"Passos por época (Validação): {val_steps_per_epoch}\" )\n",
    "\n",
    "# Treina o modelo usando os datasets separados e validation_data\n",
    "print( \"DataLoaders PyTorch criados.\" )\n",
    "\n",
    "# O Keras Model `fit` pode aceitar DataLoaders PyTorch diretamente com o backend Torch\n",
    "history = bert_masked_model.fit(\n",
    "        train_loader,  # Passa o DataLoader de treino\n",
    "        validation_data = val_loader,  # Passa o DataLoader de validação\n",
    "        epochs = 1,\n",
    "        callbacks = [ generator_callback ]  # Mantém o callback\n",
    ")\n",
    "\n",
    "bert_masked_model.save( \"bert_mlm.keras\" )\n",
    "print( \"\\nTreinamento concluído e modelo salvo!\" )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passos por época (Treino): 90\n",
      "Passos por época (Validação): 22\n",
      "DataLoaders PyTorch criados.\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2s/step - loss: 10.1241\n",
      "--- Predição Exemplo Callback (Época 1) ---\n",
      "Texto de Entrada: [UNK] e [mask]\n",
      "{'predicted_mask_token': np.str_('o'),\n",
      " 'prediction': '[UNK] e o',\n",
      " 'probability': 0.00036310646100901067}\n",
      "{'predicted_mask_token': np.str_('não'),\n",
      " 'prediction': '[UNK] e não',\n",
      " 'probability': 0.000353536190232262}\n",
      "{'predicted_mask_token': np.str_('eu'),\n",
      " 'prediction': '[UNK] e eu',\n",
      " 'probability': 0.000330655399011448}\n",
      "{'predicted_mask_token': np.str_('você'),\n",
      " 'prediction': '[UNK] e você',\n",
      " 'probability': 0.00032105844002217054}\n",
      "{'predicted_mask_token': np.str_('me'),\n",
      " 'prediction': '[UNK] e me',\n",
      " 'probability': 0.0003188711707480252}\n",
      "--- Fim Predição Exemplo Callback ---\n",
      "\u001B[1m91/91\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m233s\u001B[0m 3s/step - loss: 10.1209 - val_loss: 8.9241\n",
      "\n",
      "Treinamento concluído e modelo salvo!\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:57:43.704382Z",
     "start_time": "2025-04-09T13:57:43.580917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plotar histórico de loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'loss' in history.history and 'val_loss' in history.history:\n",
    "    plt.plot( history.history[ 'loss' ], label = 'Training Loss' )\n",
    "    plt.plot( history.history[ 'val_loss' ], label = 'Validation Loss' )\n",
    "    plt.title( 'Training and Validation Loss' )\n",
    "    plt.xlabel( 'Epoch' )\n",
    "    plt.ylabel( 'Loss' )\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print( \"Não foi possível plotar o gráfico de perdas. Verifique as chaves em 'history.history':\",\n",
    "           history.history.keys()\n",
    "           )\n"
   ],
   "id": "80d9bb8dbdfce5b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:57:43.720405Z",
     "start_time": "2025-04-09T13:57:43.714399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Retoma o treinamento\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Carrega o modelo salvo\n",
    "if 0:\n",
    "    bert_mlm_model = load_model( \"bert_mlm.keras\" )\n",
    "    bert_mlm_model.fit( mlm_ds.repeat(), epochs = 5, steps_per_epoch = steps, callbacks = [ generator_callback ] )"
   ],
   "id": "54e2be6bf43e279a",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Predição de Frases\n",
    "\n",
    "Utilização do modelo treinado para realizar a predição de novas frases."
   ],
   "id": "a5c8af1d595f4aa2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:57:43.767922Z",
     "start_time": "2025-04-09T13:57:43.754922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Função para prever o token mascarado e mostrar top K predições\n",
    "def predict_masked_token( text_with_mask: str, model, vectorize_layer, id2token, top_k = 5 ):\n",
    "    \"\"\"\n",
    "    Prevê o token mascarado em uma frase e retorna as top K previsões com probabilidades.\n",
    "\n",
    "    Args:\n",
    "        text_with_mask (str): A frase de entrada contendo exatamente um token '[mask]'.\n",
    "        model (keras.Model): O modelo treinado (MLM).\n",
    "        vectorize_layer (TextVectorization): A camada de vetorização JÁ ADAPTADA.\n",
    "        id2token (dict): Dicionário mapeando ID para token.\n",
    "        top_k (int): Quantidade de melhores previsões a serem mostradas.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame com as top K previsões, tokens e probabilidades.\n",
    "                         Retorna None se '[mask]' não for encontrado ou mais de um for encontrado.\n",
    "    \"\"\"\n",
    "    # 1. Vetorizar a frase de entrada\n",
    "    #    O reshape [1, -1] adiciona a dimensão do batch (lote de tamanho 1)\n",
    "    sample_tokens = vectorize_layer( [ text_with_mask ] )  # Não precisa de .numpy() aqui para predict\n",
    "\n",
    "    # Verifica se a vetorização retornou algo e se tem o formato esperado\n",
    "    if sample_tokens is None or sample_tokens.shape[ 0 ] == 0:\n",
    "        print( \"Erro: A vetorização não produziu uma saída válida.\" )\n",
    "        return None\n",
    "\n",
    "    # 2. Encontrar o índice do token [mask]\n",
    "    #    `.numpy()` converte o tensor para numpy array para usar np.where\n",
    "    #    Pega o id do token de máscara global que definimos antes\n",
    "    masked_index_tuple = np.where( sample_tokens.cpu().numpy()[ 0 ] == mask_token_id )\n",
    "\n",
    "    # Verifica se encontrou o token de máscara e se é apenas um\n",
    "    if len( masked_index_tuple[ 0 ] ) != 1:\n",
    "        print(\n",
    "                f\"Erro: Esperado exatamente um token '[mask]' na frase vetorizada, mas encontrado(s) {len( masked_index_tuple[ 0 ] )}.\"\n",
    "        )\n",
    "        print( f\"Frase vetorizada: {sample_tokens.numpy()[ 0 ]}\" )\n",
    "        print( f\"ID esperado para [mask]: {mask_token_id}\" )\n",
    "        # Tenta decodificar para ajudar a depurar\n",
    "        try:\n",
    "            decoded_tokens = [ id2token.get( int( t ), \"[UNK]\" ) for t in sample_tokens.numpy()[ 0 ] if t != 0 ]\n",
    "            print( f\"Tokens decodificados: {' '.join( decoded_tokens )}\" )\n",
    "        except Exception as e:\n",
    "            print( f\"Não foi possível decodificar os tokens: {e}\" )\n",
    "        return None\n",
    "\n",
    "    masked_index = masked_index_tuple[ 0 ][ 0 ]  # Pega o índice escalar\n",
    "\n",
    "    # 3. Fazer a predição com o modelo\n",
    "    prediction = model.predict( sample_tokens )\n",
    "\n",
    "    # 4. Extrair as probabilidades para a posição mascarada\n",
    "    #    prediction[0] -> batch de tamanho 1\n",
    "    #    prediction[0][masked_index] -> probabilidades para o token na posição mascarada\n",
    "    mask_prediction_probabilities = prediction[ 0 ][ masked_index ]\n",
    "\n",
    "    # 5. Encontrar os top K índices e suas probabilidades\n",
    "    #    argsort() retorna os índices que ordenariam o array (do menor para o maior)\n",
    "    #    [-top_k:] pega os K maiores índices\n",
    "    #    [::-1] inverte para ter do maior para o menor\n",
    "    top_indices = mask_prediction_probabilities.argsort()[ -top_k: ][ ::-1 ]\n",
    "    top_probabilities = mask_prediction_probabilities[ top_indices ]\n",
    "\n",
    "    # 6. Converter os IDs dos tokens previstos para palavras\n",
    "    top_tokens = [ id2token.get( idx, \"[UNK]\" ) for idx in top_indices ]\n",
    "\n",
    "    # 7. Criar e retornar um DataFrame com os resultados\n",
    "    results_df = pd.DataFrame( {\n",
    "        \"Token Previsto\": top_tokens,\n",
    "        \"Probabilidade\": top_probabilities\n",
    "    }\n",
    "    )\n",
    "\n",
    "    print( f\"\\nPredições para: '{text_with_mask}'\" )\n",
    "    return results_df"
   ],
   "id": "b08a6f73cd999b58",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T13:57:43.845510Z",
     "start_time": "2025-04-09T13:57:43.790924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frase_teste_1 = \"Pra sempre com [mask]\"\n",
    "resultados_df_1 = predict_masked_token( frase_teste_1, bert_masked_model, vectorize_layer, id2token, top_k = 10 )\n",
    "\n",
    "if resultados_df_1 is not None:\n",
    "    print( resultados_df_1.to_string( index = False ) )  # .to_string para melhor formatação no print"
   ],
   "id": "c63d4fb3a3660983",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step\n",
      "\n",
      "Predições para: 'Pra sempre com [mask]'\n",
      "Token Previsto  Probabilidade\n",
      "           não       0.000368\n",
      "             o       0.000360\n",
      "            eu       0.000324\n",
      "            me       0.000314\n",
      "          você       0.000311\n",
      "             é       0.000293\n",
      "             a       0.000277\n",
      "            um       0.000259\n",
      "             e       0.000258\n",
      "           pra       0.000250\n"
     ]
    }
   ],
   "execution_count": 143
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
