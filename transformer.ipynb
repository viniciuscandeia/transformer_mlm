{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Transformer\n",
    "\n",
    "- Encoder: O Encoder recebe a sequência de entrada (por exemplo, uma frase em português) e a processa para criar uma representação vetorial de alta qualidade dessa sequência. Essa representação captura o significado e o contexto de cada palavra em relação às outras palavras da frase.\n",
    "- Decoder: O Decoder recebe a representação gerada pelo Encoder e a utiliza para gerar uma sequência de saída (por exemplo, a tradução da frase para o inglês).\n"
   ],
   "id": "e98cd1fa27373e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Masked Language Model\n",
    "\n",
    "Um Masked Language Model (MLM) é um tipo de modelo de linguagem amplamente utilizado em processamento de linguagem natural.\n",
    "\n",
    "Durante o treinamento, uma parte dos tokens (palavras ou subpalavras) no texto de entrada é substituída por um token especial de máscara, como \"[MASK]\". O objetivo do modelo é prever corretamente quais eram os tokens originais que foram mascarados.\n",
    "\n",
    "Essa estratégia obriga o modelo a aprender contextos ricos e relações entre as palavras, o que é fundamental para o desempenho em diversas tarefas, como análise de sentimentos, tradução, e resposta a perguntas. Modelos famosos que utilizam essa técnica incluem o BERT, que demonstrou ganhos significativos em várias benchmarks de NLP .\n"
   ],
   "id": "beae2a5e32306d38"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## IMBD\n",
    "\n",
    "Para este projeto, será utilizado a base do IMBD."
   ],
   "id": "a8259a8ef1b3febb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuração",
   "id": "c4bed58b15c8e73d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:11:11.011869Z",
     "start_time": "2025-04-01T22:10:39.874892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[ \"KERAS_BACKEND\" ] = \"torch\"  # or jax, or tensorflow\n",
    "\n",
    "import keras_hub\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "from pprint import pprint"
   ],
   "id": "a89620b2e2393cb4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/viniciuscandeia/development/transformer_mlm/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:11:11.033624Z",
     "start_time": "2025-04-01T22:11:11.028586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    MAX_LEN = 256\n",
    "    BATCH_SIZE = 32\n",
    "    LR = 0.001\n",
    "    VOCAB_SIZE = 30000\n",
    "    EMBED_DIM = 128\n",
    "    NUM_HEAD = 8  # used in bert model\n",
    "    FF_DIM = 128  # used in bert model\n",
    "    NUM_LAYERS = 1\n",
    "\n",
    "\n",
    "config = Config()"
   ],
   "id": "6cce974cf0c26a19",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Carregando os dados\n",
    "\n",
    "Primeiro, vamos carregar os dados que estão na pasta \"aclImbd\".\n",
    "\n",
    "Duas funções serão utilizadas para isso:\n",
    "\n",
    "- Uma irá criar uma lista contendo o conteúdo dos arquivos.\n",
    "- A outra ficará responsável por criar um dataframe."
   ],
   "id": "39422ab42f331838"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:11:20.256646Z",
     "start_time": "2025-04-01T22:11:11.043602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_text_list_from_files( files ) -> list[ str ]:\n",
    "    \"\"\"\n",
    "       Esta função irá retornar uma lista contendo todas as frases dos arquivos.\n",
    "    \"\"\"\n",
    "    text_list: list[ str ] = [ ]\n",
    "    for name in files:\n",
    "        with open( name ) as f:\n",
    "            for line in f:\n",
    "                text_list.append( line )\n",
    "    return text_list\n",
    "\n",
    "\n",
    "def get_data_from_text_files( folder_name ):\n",
    "    # Arquivos de texto com avaliações positivas e negativas\n",
    "    pos_files = glob.glob( f\"aclImdb/{folder_name}/pos/*.txt\" )\n",
    "    neg_files = glob.glob( f\"aclImdb/{folder_name}/neg/*.txt\" )\n",
    "\n",
    "    # Listas com as avaliações\n",
    "    pos_texts: list[ str ] = get_text_list_from_files( pos_files )\n",
    "    neg_texts: list[ str ] = get_text_list_from_files( neg_files )\n",
    "\n",
    "    # Criação de um dataframe, com colunas chamadas \"review\" e \"sentiment\"\n",
    "    df = pd.DataFrame(\n",
    "            {\n",
    "                # Concatenação das listas\n",
    "                \"review\": pos_texts + neg_texts,\n",
    "                # Criação de uma nova lista\n",
    "                \"sentiment\": [ 0 ] * len( pos_texts ) + [ 1 ] * len( neg_texts ),\n",
    "            }\n",
    "    )\n",
    "\n",
    "    # Sample -> pega uma amostra aleatória\n",
    "    # len(df) -> do tamanho do df original\n",
    "    # reset_index -> ao usar sample, o índice original das linhas é mantido\n",
    "    df = df.sample( len( df ) ).reset_index( drop = True )\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = get_data_from_text_files( \"train\" )\n",
    "test_df = get_data_from_text_files( \"test\" )\n",
    "\n",
    "# Concatenação dos dataframes para realizar pré-processamento em toda a base\n",
    "all_data = pd.concat( [ train_df, test_df ], ignore_index = True )"
   ],
   "id": "822b332050609de1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:11:20.514507Z",
     "start_time": "2025-04-01T22:11:20.497906Z"
    }
   },
   "cell_type": "code",
   "source": "train_df.head()",
   "id": "aa3089bbffe5c2b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              review  sentiment\n",
       "0  This movie is a classic in every sense of the ...          0\n",
       "1  Even if you could get past the idea that these...          1\n",
       "2  First let me preface this post by saying that ...          1\n",
       "3  \"The Incredible Melting Man\" is a fantasticall...          0\n",
       "4  this movie was clearly done poorly and in a ru...          1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This movie is a classic in every sense of the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Even if you could get past the idea that these...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First let me preface this post by saying that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"The Incredible Melting Man\" is a fantasticall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this movie was clearly done poorly and in a ru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:11:20.809777Z",
     "start_time": "2025-04-01T22:11:20.797393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def custom_standardization( input_data ):\n",
    "    \"\"\"\n",
    "        Normalização de texto.\n",
    "    \"\"\"\n",
    "    # Converter todas as letras para minúsculas\n",
    "    lowercase = tf.strings.lower( input_data )\n",
    "\n",
    "    # Expressão Regular para remover a tag HTML\n",
    "    stripped_html = tf.strings.regex_replace( lowercase, \"<br />\", \" \" )\n",
    "\n",
    "    # Remover caracteres especiais\n",
    "    return tf.strings.regex_replace(\n",
    "            stripped_html,\n",
    "            \"[%s]\" % re.escape( \"!#$%&'()*+,-./:;<=>?@\\^_`{|}~\" ),\n",
    "            \"\"\n",
    "    )"
   ],
   "id": "e617962188106c4a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vetorização de Texto\n",
    "\n",
    "Para um transformer, a vetorização de um texto é o processo fundamental de transformar o texto bruto em uma representação numérica que o modelo possa entender e processar. Em essência, é como traduzir a linguagem humana para a linguagem matemática que o transformer consegue trabalhar.\n",
    "\n",
    "Imagine que o transformer é um computador que só entende números. Para que ele consiga ler e compreender um texto, precisamos converter cada palavra (ou parte da palavra) em um conjunto de números. Esse conjunto de números é o que chamamos de vetor.\n",
    "\n",
    "Aqui está um detalhamento do processo de vetorização para um transformer:\n",
    "\n",
    "1. Tokenização: O primeiro passo é dividir o texto em unidades menores, chamadas tokens. Um token pode ser uma palavra inteira, parte de uma palavra (subpalavra), ou até mesmo um caractere. Por exemplo, a frase \"O gato comeu o rato\" poderia ser tokenizada como: [\"O\", \"gato\", \"comeu\", \"o\", \"rato\"].\n",
    "\n",
    "2. Criação do Vocabulário: Em seguida, é criado um vocabulário, que é uma lista de todos os tokens únicos presentes no conjunto de dados de treinamento do modelo. Cada token nesse vocabulário recebe um índice único.\n",
    "\n",
    "3. Indexação: Cada token no texto de entrada é então mapeado para o seu índice correspondente no vocabulário. Usando o exemplo anterior e supondo um vocabulário, os tokens poderiam ser convertidos em índices como: [10, 25, 50, 10, 75].\n",
    "\n",
    "4. Embedding: A etapa crucial para transformers é a criação de embeddings. Em vez de simplesmente usar os índices brutos, cada índice é transformado em um vetor denso de números reais. Esse vetor captura o significado semântico e as relações entre as palavras.\n",
    "\n",
    "    - Word Embeddings: Cada palavra (ou token) é associada a um vetor de baixa dimensionalidade (por exemplo, 512 ou 768 dimensões). Palavras com significados semelhantes tendem a ter vetores próximos no espaço vetorial. Por exemplo, os vetores para \"gato\" e \"felino\" provavelmente estarão mais próximos do que os vetores para \"gato\" e \"carro\".\n",
    "\n",
    "    - Positional Embeddings: Transformers também precisam entender a ordem das palavras em uma frase. Para isso, são adicionados embeddings posicionais aos word embeddings. Esses vetores codificam a posição de cada token na sequência, permitindo que o modelo diferencie entre \"o gato comeu o rato\" e \"o rato comeu o gato\".\n",
    "\n",
    "5. Input para o Transformer: Os vetores resultantes (a soma dos word embeddings e positional embeddings para cada token) são então alimentados como entrada para as diferentes camadas do transformer (como as camadas de atenção)."
   ],
   "id": "1413c85f5980aae3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:11:21.069371Z",
     "start_time": "2025-04-01T22:11:21.056371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_vectorize_layer( texts: list[ str ], vocab_size: int, max_seq: int, special_tokens: list = [ \"[MASK]\" ] ):\n",
    "    \"\"\"Build Text vectorization layer\n",
    "\n",
    "    Args:\n",
    "      texts (list): List of string i.e input texts\n",
    "      vocab_size (int): vocab size\n",
    "      max_seq (int): Maximum sequence length.\n",
    "      special_tokens (list, optional): List of special tokens. Defaults to ['[MASK]'].\n",
    "\n",
    "    Returns:\n",
    "        layers.Layer: Return TextVectorization Keras Layer\n",
    "    \"\"\"\n",
    "    vectorize_layer = TextVectorization(\n",
    "            max_tokens = vocab_size,\n",
    "            output_mode = \"int\",\n",
    "            standardize = custom_standardization,\n",
    "            output_sequence_length = max_seq,\n",
    "    )\n",
    "    vectorize_layer.adapt( texts )\n",
    "\n",
    "    # Insert mask token in vocabulary\n",
    "    vocab = vectorize_layer.get_vocabulary()\n",
    "    vocab = vocab[ 2: vocab_size - len( special_tokens ) ] + [ \"[mask]\" ]\n",
    "    vectorize_layer.set_vocabulary( vocab )\n",
    "    return vectorize_layer"
   ],
   "id": "7d8904fb48419e91",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
